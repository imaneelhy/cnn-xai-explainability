import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as T
import matplotlib.pyplot as plt

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", DEVICE)

# CIFAR-10 normalization
mean = (0.4914, 0.4822, 0.4465)
std = (0.2470, 0.2435, 0.2616)

transform_train = T.Compose([
    T.RandomHorizontalFlip(),
    T.RandomCrop(32, padding=4),
    T.ToTensor(),
    T.Normalize(mean, std),
])

transform_test = T.Compose([
    T.ToTensor(),
    T.Normalize(mean, std),
])

train_set = torchvision.datasets.CIFAR10(
    root="./data", train=True, download=True, transform=transform_train
)
test_set = torchvision.datasets.CIFAR10(
    root="./data", train=False, download=True, transform=transform_test
)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)
# separate loader with batch_size=1 for explanations
explain_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)

classes = train_set.classes
print("Classes:", classes)


from torchvision import models

def get_resnet18_cifar10(num_classes=10):
    model = models.resnet18(weights=None)
    # adapt for 32x32
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
    model.maxpool = nn.Identity()
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

model = get_resnet18_cifar10().to(DEVICE)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)

def train_epoch(epoch):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for i, (inputs, targets) in enumerate(train_loader):
        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

    print(f"Epoch {epoch}: loss={running_loss/len(train_loader):.3f}, "
          f"acc={100.*correct/total:.2f}%")

def test_model():
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
    acc = 100.*correct/total
    print(f"Test acc: {acc:.2f}%")
    return acc

# Train just a few epochs for demo (you can increase)
for epoch in range(1, 6):
    train_epoch(epoch)
    test_model()

# save checkpoint (useful later)
torch.save(model.state_dict(), "resnet18_cifar10.pth")


# -------------------- XAI METHODS --------------------

# Grad-CAM
class GradCAM:
    def __init__(self, model, target_layer_name: str):
        self.model = model
        self.target_layer = dict([*model.named_modules()])[target_layer_name]

        self.activations = None
        self.gradients = None

        self.fwd_hook = self.target_layer.register_forward_hook(self._forward_hook)
        # modern API instead of deprecated register_backward_hook
        self.bwd_hook = self.target_layer.register_full_backward_hook(self._backward_hook)

    def _forward_hook(self, module, input, output):
        self.activations = output.detach()

    def _backward_hook(self, module, grad_input, grad_output):
        self.gradients = grad_output[0].detach()

    def generate(self, input_tensor: torch.Tensor, target_class: int):
        """
        input_tensor: (1, C, H, W)
        """
        self.model.zero_grad()
        logits = self.model(input_tensor)
        score = logits[:, target_class]
        score.backward(retain_graph=True)

        grads = self.gradients     # (1, C, H, W)
        activations = self.activations  # (1, C, H, W)

        weights = grads.mean(dim=(2, 3), keepdim=True)  # (1, C, 1, 1)
        cam = (weights * activations).sum(dim=1)        # (1, H, W)

        cam = F.relu(cam)
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        return cam  # (1, H, W)

    def remove_hooks(self):
        self.fwd_hook.remove()
        self.bwd_hook.remove()


# Saliency maps
def compute_saliency(model, input_tensor: torch.Tensor, target_class: int):
    input_tensor = input_tensor.clone().detach()
    input_tensor.requires_grad_(True)

    model.zero_grad()
    logits = model(input_tensor)
    score = logits[:, target_class]
    score.backward()

    gradient = input_tensor.grad.data  # (1, C, H, W)
    saliency = gradient.abs().max(dim=1)[0]  # (1, H, W)
    saliency = saliency.squeeze(0)

    saliency -= saliency.min()
    saliency /= (saliency.max() + 1e-8)
    return saliency

# Integrated Gradients
def integrated_gradients(model, input_tensor: torch.Tensor, target_class: int,
                         baseline: torch.Tensor = None, steps: int = 50):
    device = input_tensor.device
    if baseline is None:
        baseline = torch.zeros_like(input_tensor).to(device)

    scaled_inputs = [
        baseline + (float(i) / steps) * (input_tensor - baseline)
        for i in range(1, steps + 1)
    ]
    scaled_inputs = torch.cat(scaled_inputs, dim=0)
    scaled_inputs.requires_grad_(True)

    model.zero_grad()
    logits = model(scaled_inputs)
    target_scores = logits[:, target_class].sum()
    target_scores.backward()

    grads = scaled_inputs.grad  # (steps, C, H, W)
    avg_grads = grads.mean(dim=0, keepdim=True)  # (1, C, H, W)

    attributions = (input_tensor - baseline) * avg_grads  # (1, C, H, W)
    attributions = attributions.sum(dim=1).squeeze(0)  # (H, W)
    attributions = attributions.clamp(min=0)

    attributions -= attributions.min()
    attributions /= (attributions.max() + 1e-8)
    return attributions


def flatten_and_normalize(map1, map2):
    m1 = map1.float().view(-1)
    m2 = map2.float().view(-1)
    m1 = (m1 - m1.min()) / (m1.max() - m1.min() + 1e-8)
    m2 = (m2 - m2.min()) / (m2.max() - m2.min() + 1e-8)
    return m1, m2

def pearson_correlation(map1, map2):
    m1, m2 = flatten_and_normalize(map1, map2)
    m1 = m1 - m1.mean()
    m2 = m2 - m2.mean()
    num = (m1 * m2).sum()
    den = (m1.norm() * m2.norm() + 1e-8)
    return (num / den).item()

def iou_topk(map1, map2, k=0.2):
    m1, m2 = flatten_and_normalize(map1, map2)
    n = m1.numel()
    topk = int(max(1, k * n))

    thresh1 = torch.topk(m1, topk).values.min()
    thresh2 = torch.topk(m2, topk).values.min()

    mask1 = (m1 >= thresh1)
    mask2 = (m2 >= thresh2)

    inter = (mask1 & mask2).sum().float()
    union = (mask1 | mask2).sum().float() + 1e-8
    return (inter / union).item()


# de-normalize helper
def denormalize(img_tensor, mean, std):
    mean = torch.tensor(mean).view(3, 1, 1).to(img_tensor.device)
    std = torch.tensor(std).view(3, 1, 1).to(img_tensor.device)
    return img_tensor * std + mean

# -------------------- GENERATE EXPLANATIONS --------------------

grad_cam = GradCAM(model, target_layer_name="layer4")

pearson_scores = {"gc_sal": [], "gc_ig": [], "sal_ig": []}
iou_scores = {"gc_sal": [], "gc_ig": [], "sal_ig": []}

model.eval()
num_samples = 5        # number of correctly classified images to explain
explained = 0

for idx, (img, label) in enumerate(explain_loader):
    if explained >= num_samples:
        break

    img, label = img.to(DEVICE), label.to(DEVICE)

    # forward pass to get prediction
    with torch.no_grad():
        logits = model(img)
        pred = logits.argmax(dim=1)

    # only explain correctly classified images
    if pred.item() != label.item():
        continue

    x = img              # shape (1, 3, 32, 32)
    target_class = pred.item()

    # Grad-CAM
    cam = grad_cam.generate(x, target_class)[0]  # (Hc, Wc)
    cam_up = F.interpolate(
        cam.unsqueeze(0).unsqueeze(0),
        size=(32, 32),
        mode="bilinear",
        align_corners=False
    ).squeeze()

    # Saliency
    sal = compute_saliency(model, x, target_class)

    # Integrated Gradients
    ig = integrated_gradients(model, x, target_class, steps=32)

    # metrics
    pearson_scores["gc_sal"].append(pearson_correlation(cam_up, sal))
    pearson_scores["gc_ig"].append(pearson_correlation(cam_up, ig))
    pearson_scores["sal_ig"].append(pearson_correlation(sal, ig))

    iou_scores["gc_sal"].append(iou_topk(cam_up, sal))
    iou_scores["gc_ig"].append(iou_topk(cam_up, ig))
    iou_scores["sal_ig"].append(iou_topk(sal, ig))

    # visualization
    img_denorm = denormalize(x[0].cpu(), mean, std).clamp(0, 1)
    img_np = img_denorm.permute(1, 2, 0).cpu().numpy()

    fig, axs = plt.subplots(1, 4, figsize=(12, 3))
    axs[0].imshow(img_np)
    axs[0].set_title(f"Original\npred: {classes[target_class]}")
    axs[0].axis("off")

    axs[1].imshow(img_np)
    axs[1].imshow(cam_up.cpu().numpy(), cmap="jet", alpha=0.4)
    axs[1].set_title("Grad-CAM")
    axs[1].axis("off")

    axs[2].imshow(img_np)
    axs[2].imshow(sal.cpu().numpy(), cmap="jet", alpha=0.4)
    axs[2].set_title("Saliency")
    axs[2].axis("off")

    axs[3].imshow(img_np)
    axs[3].imshow(ig.cpu().numpy(), cmap="jet", alpha=0.4)
    axs[3].set_title("Integrated Gradients")
    axs[3].axis("off")

    plt.tight_layout()
    plt.show()

    explained += 1

grad_cam.remove_hooks()

print("Number of explained images:", explained)

print("Average Pearson:")
print("GC vs Sal:", sum(pearson_scores["gc_sal"])/len(pearson_scores["gc_sal"]))
print("GC vs IG :", sum(pearson_scores["gc_ig"])/len(pearson_scores["gc_ig"]))
print("Sal vs IG:", sum(pearson_scores["sal_ig"])/len(pearson_scores["sal_ig"]))

print("Average IoU:")
print("GC vs Sal:", sum(iou_scores["gc_sal"])/len(iou_scores["gc_sal"]))
print("GC vs IG :", sum(iou_scores["gc_ig"])/len(iou_scores["gc_ig"]))
print("Sal vs IG:", sum(iou_scores["sal_ig"])/len(iou_scores["sal_ig"]))
